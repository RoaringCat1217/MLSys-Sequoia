Namespace(draft_model='meta-llama/Llama-2-7b-hf', tiny_model='JackFram/llama-68m', target='meta-llama/Llama-2-13b-hf', dataset='cnn', start=0, end=200, seed=17, M=384, S=128, offloading=False, n_spec=128, spec_steps=6, eps=0.2)
Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:38<00:00, 19.25s/it]
Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:10<00:00, 23.50s/it]
/root/MLSys-Sequoia/utils.py:252: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  static_probs = torch.nn.functional.softmax(static_logits)
/root/MLSys-Sequoia/utils.py:259: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  static_probs = torch.nn.functional.softmax(static_logits)
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [11:52<00:00,  3.56s/it]
total time :708.68156s, latency :0.01403s, decoding step: 50502, large model step: 10466, 4.825339193579209
